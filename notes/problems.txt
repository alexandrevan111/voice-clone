Problems:
- VC2 has mixed languages and I cannot seem to find labels for those anywhere. For the lack of consistency, VC1 also has mixed languages but I did have the labels there and was able to prune them out.
    * Try to find the labels to exclude them:
        o It's less data, but it's better data
        * I sent a mail to the authors on the 5th of february
        * I googled and asked /r/datasets to no avail.
        * I can go for language guessing using youtube's title and description, but that's a poor approach
        * Language detection through voice would be great
            - It might be slow to run on the entire dataset
            - It may just be weak as well
    * Include the different languages anyway:
        + No effort of filtering non-English out
        o It's apparently what the authors did as well when they reported the EER in the table, but their final model uses their internal dataset which is full English. I wouldn't even be surprised if they never noticed there is non-English speech in VC.
        - That may just weaken the ability of the model to distinguish among English speakers
        - It's not the appropriate meaning for the embeddings: the language will likely be encoded but Tacotron is meant to synthesize English only.

* Meaning of the embedding for a sentence, non normalized, duration

- Embedding for a sentence of 